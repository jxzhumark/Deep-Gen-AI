# Deep-Gen-AI
This repo records my work on deep generative AI, including but not limited to, scalable modeling, efficient training and fast inference, etc.
引入 (Dr Lu Cheng's thesis)：
深度学习可以分为：
1. 判别式建模：利用标注数据进行监督学习，例如图像分类
2. 生成式建模：学习数据的分布，然后进行生成，例如GPT；生成式建模无需额外的数据标注,而是直接建模数据对应的分布,且可以充分利用互联网上的所有数据
![image](https://github.com/user-attachments/assets/5639fb9d-cc84-4373-bc31-f7b0a01de870)

生成式建模的三点基本问题：

模型表达能力：定义参数空间以及模型分布；参数空间由神经网络定义，然后模型分布直接由深度生成模型的类型决定；总体而言,深度  生成模型需要尽可能地提高模型的表达能力,以匹配复杂的数据分布。
显式深度生成模型：
1. 自回归模型
2. 变分自编码器
3. 标准化流模型，离散时间和连续时间
4. 能量模型
5. 扩散模型
隐式深度生成模型：没有p（x，\theta）的显式表达，而是定义了采样过程/生成器
1. 生成对抗网络

训练算法/训练难度：由于不同类型的深度生  成模型的表达能力不同,其训练难度(寻找到最优解的难度)也不同；需要设计稳定且易于扩展的训练算法，使得模型可以高效地发挥其理论上的表达能力
1. GAN需要引入额外的判别器借助对抗训练来监督生成器；训练不稳地
2. VAE需要引入额外的变分后验来最大化数据对数似然的下界
3. 能量模型需要利用分数匹配来估计数据的分数函数；但是在第密度区域训练难度很大
4. 自回归模型由于缺乏对高纬度数据的冗余信息的先验，其在图像数据的训练难度通常远远大于其他生成模型
5. 连续时间标准化流的每一步训练优化都需要借助ODE求解器，训练较慢
6. 离散化标准化流可以高效计算LLF，训练难度低
7. 扩散模型只需要预测数据的噪声，训练目标函数是一个非常简单且稳定的均方误差，因此容易扩展到高维数据

推断算法/速度与准度：计算对数似然以及采样得到新的数据
速度：
1.GAN和VAE子需要首先采样隐变量，然后输入生成器即可得到新样本，速度很快
2.自回归模型、能量模型、扩散模型和连续时间标准化流模型都需要迭代采样，推断速度慢
准度
1.GAN和EBM无法准确计算数据的对数似然；VAE只能计算数据对数似然的下界；推断准度较低
2.自回归模型、标准化流模型和扩散模型都可以准确计算数据的对数似然

根据深度生成模型钟隐变量和数据变量之间的映射种类；根据采样过程对应映射的可逆性,深度生成模型可以被分为不可逆生成模型和可逆生成模型。其中,不可逆生成模型训练难度较大,且通常难以进行准确的似然推断;反之,可逆生成模型可以计算准确的似然,且表达能力和训练稳定性都较好,因而在众多复杂高维数据建模任务中展现了优异的性能。
深度生成模型可以分为
1.可逆生成模型
NFBM
Diffusion model
2.不可逆生成模型
GAN
VAE
EBM
auto-regressive model
![image](https://github.com/user-attachments/assets/137a8f43-c740-48e7-9989-b6155dd7a16d)

可逆生成模型在许多任务的表达都很出色，具有很大潜力，但是模型一个优秀的可逆生成建模方法还有待进一步研究：
由于需要保证可逆性，模型表达能力往往与推理速度相互联系。


## Current development
### Scalable Modeling
1. EBM
2. Normalizing Flow Model
3. DDPM
4. DDIM
5. EDM
6. Consistency model

### Efficient Training
1. Simulation Free
2. 

### Fast Inference
1. ODE solve
2. SDE solve
